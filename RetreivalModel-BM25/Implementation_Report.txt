############################################################################################################
#######################################       Implementation       #########################################
############################################################################################################

 
 Lucene:
 	
 	> On running the code HW4.java the program asks the user to input the full path where the user wants the 
 	  index to be created.
 	> After entering the path for index creation, the program asks the user to input the full path of the corpus
 	  where the user wants to add into the index.
 	> Upon entering the path of the corpus, Lucene adds all the documents in the index, and again loop to ask 
 	  if the user wants to add more documents into the index. 
 	> The user has the option to enter the path of more documents or quit by entering the keyword 'q' to exit.
 	> After the user enters 'q', the program then asks the user for full path of the file that contains the list of 
 	  queries for which the user wants to generate top 100 searched documents.
 	> After entering the path of the query file the program generates the file Top_100_Query_Result_Lucene.txt that
 	  contains the top 100 search results generated by Lucene's simple analyzer.
 	> Note: Some queries generate less than 100 search results.
 	
 
 BM25:
  	
  	> To implement the BM25 search and ranking algorithm we need some pre-generated values.
  		1. Unigram index, which was calculated in previous assignment, we use the pickle file
  		   of the data structure storing the index to directly load it into the memory from disk.
  		2. The data for number of tokens per document which was also calculated in the previous assignment.
  		   This was loaded into the memory from disk using the pickle file.
  		3. The list of queries for the search operation which is fetched by reading from the ListOfQuery.txt file.
  		4. For each query fetched from the list of queries we generate term frequency and store the frequency of 
  		   each term corresponding to the term in a dictionary as key value pair.
 
  	> Now for each query fetched from the file we call the method calculateBM25Score for calculating the score for each
  	  document that contains the terms mentioned in the query using the below formula.
  	   
  	     sum over i E Q log (((ri +0.5)/(R-ri+0.5))/(ni- ri +0.5)/(N-ni-R+ri+0.5)) * (k1+1)fi/K+fi  *  (k2+1)qfi/k2+qfi
  	     
  	     where k1 = 1.2, k2 = 100 
  	     K = k1((1-b)+b*dl/avdl)
  	     where b = 0.75
  	     
  	     k1, k2, b are parameters.
  	     
  	     r and R = 0 if no relevance info is present
  	      
  	     N   = is total number of documents in the corpus, calculated by taking the length of the noOfTokensPerDoc dictionary
  	     ni  = is number of documents in which the given term wi occurs, this calculated by taking the length of the 
  	           inverted list of that term wi
  	     fi  = is the frequency of the term that occur in each document, this value is stored in the inverted index
  	           for each term occurring in each document.
  	     qfi = is frequency of the query term fetched from the term frequency dictionary generated earlier.
  	     dl  = is the length of the document, this value is collected by fetch the value from the noOfTokensPerDoc dictionary
  	           generated earlier. (eg. noOfTokensPerDoc[doc])
  	     avdl = is the average length of the documents in the corpus, this is calculated by summing all the values of 
  	     		noOfTokensPerDoc dictionary and then dividing it by N that is the number of documents in the corpus.
  	           
  	           
  	     The above values are calculated for each term present in the query and the score for the document is calculated
  	     by summing the score for each term present in the query as well as in the document.
  	     The score of each document is stored in a dictionary and is updated for each query term.
  	     
  	     The method calculateBM25Score return the final dictionary storing the document score 
  	     The method writeResultToFile sorts the score of the documents in decreasing order and writes the top 100 result
  	     (if the search returns more than 100 results or whatever result if below 100) for each query.       
  	     

